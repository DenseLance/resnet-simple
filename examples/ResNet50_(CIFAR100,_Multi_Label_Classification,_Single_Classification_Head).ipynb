{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "buw-O1vs3PHS"
   },
   "outputs": [],
   "source": [
    "# Remember to mount your Google Drive before proceeding!\n",
    "!pip install -i https://test.pypi.org/simple/ resnet-simple -q\n",
    "!pip install nvidia-ml-py -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qpT76WDl8qBA"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import random\n",
    "import pynvml\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Optional, Callable\n",
    "from sklearn import metrics\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from resnet_simple import ResNet50, ResNetPredictor\n",
    "\n",
    "# To insert your own folder directory\n",
    "MODEL_FOLDER = \"Models/\"\n",
    "\n",
    "def calculate_gpu_utilization(gpu_index: int = 0):\n",
    "    pynvml.nvmlInit()\n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(gpu_index)\n",
    "    info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used // 1024 ** 2} MB.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ha6F2dSMIWLl"
   },
   "source": [
    "# Train ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XpizmWcgHUbU"
   },
   "outputs": [],
   "source": [
    "# Another method to consider (which should yield much better results) would be having a second classification head for the coarse labels\n",
    "class ModifiedCIFAR100(datasets.CIFAR100):\n",
    "    def __init__(self, root: str, train: bool = True, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False):\n",
    "        super().__init__(root, train, transform, target_transform, download)\n",
    "        # Can be loaded via __init__(), under entry[\"coarse_labels\"], similar to how fine labels are obtained via entry[\"fine_labels\"]\n",
    "        self.fine_to_coarse_map = torch.tensor([\n",
    "            4, 1, 14, 8, 0, 6, 7, 7, 18, 3, 3, 14, 9, 18, 7, 11, 3, 9, 7, 11, 6,\n",
    "            11, 5, 10, 7, 6, 13, 15, 3, 15, 0, 11, 1, 10, 12, 14, 16, 9, 11, 5, 5,\n",
    "            19, 8, 8, 15, 13, 14, 17, 18, 10, 16, 4, 17, 4, 2, 0, 17, 4, 18, 17,\n",
    "            10, 3, 2, 12, 12, 16, 12, 1, 9, 19, 2, 10, 0, 1, 16, 12, 9, 13, 15, 13,\n",
    "            16, 19, 2, 4, 6, 19, 5, 5, 8, 19, 18, 1, 2, 15, 6, 0, 17, 8, 14, 13\n",
    "        ])\n",
    "        # Can be loaded via _load_meta()'s data[\"coarse_label_names\"], similar to how fine labels are obtained via data[self.meta[\"key\"]], where self.meta[\"key\"] == \"fine_label_names\"\n",
    "        self.superclasses = [\n",
    "            \"aquatic_mammals\",\n",
    "            \"fish\",\n",
    "            \"flowers\",\n",
    "            \"food_containers\",\n",
    "            \"fruit_and_vegetables\",\n",
    "            \"household_electrical_devices\",\n",
    "            \"household_furniture\",\n",
    "            \"insects\",\n",
    "            \"large_carnivores\",\n",
    "            \"large_man-made_outdoor_things\",\n",
    "            \"large_natural_outdoor_scenes\",\n",
    "            \"large_omnivores_and_herbivores\",\n",
    "            \"medium_mammals\",\n",
    "            \"non-insect_invertebrates\",\n",
    "            \"people\",\n",
    "            \"reptiles\",\n",
    "            \"small_mammals\",\n",
    "            \"trees\",\n",
    "            \"vehicles_1\",\n",
    "            \"vehicles_2\"\n",
    "        ]\n",
    "        # Append superclasses to the end of class list, such that there are 2 labels tagged to 1 image\n",
    "        # Technically the laziest solution out there, but this counts as a Multi-Label Classification\n",
    "        # The best solution is to use another classification head to predict the superclasses instead\n",
    "        # Note that we use Sigmoid instead of Softmax for evaluation as it provides us with topk results based on the user-defined threshold\n",
    "        # Also bounds logits to (0, 1) and generally we use threshold of 0.5 to split output as 0 or 1\n",
    "        self.fine_to_coarse_map += len(self.classes)\n",
    "        self.classes.extend(self.superclasses)\n",
    "        # One-hot encoding to feed to NN\n",
    "        #self.coarse_targets = torch.nn.functional.one_hot(torch.tensor(self.targets[]), num_classes = len(self.classes))\n",
    "        self.targets = torch.tensor(self.targets)\n",
    "        one_hot_targets = torch.nn.functional.one_hot(self.targets, num_classes = len(self.classes))\n",
    "        one_hot_targets[torch.arange(one_hot_targets.shape[0]), self.fine_to_coarse_map[self.targets]] = 1\n",
    "        self.targets = one_hot_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C2MiUT0IA63e"
   },
   "outputs": [],
   "source": [
    "mean, std = [0.50707516, 0.48654887, 0.44091784], [0.26733429, 0.25643846, 0.27615047]\n",
    "batch_size = 256\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p = 0.5),\n",
    "    transforms.RandomCrop(32, padding = 4),\n",
    "    transforms.RandAugment(num_ops = 2, magnitude = 9),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "train = ModifiedCIFAR100(root = \"sample_data/cifar\", download = True, train = True, transform = transform_train)\n",
    "trainloader = DataLoader(train, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "test = ModifiedCIFAR100(root = \"sample_data/cifar\", download = True, train = False, transform = transform_test)\n",
    "testloader = DataLoader(test, batch_size = batch_size)\n",
    "\n",
    "calculate_gpu_utilization(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J3BfiAR6B-ID"
   },
   "outputs": [],
   "source": [
    "resnet = ResNet50()\n",
    "\n",
    "# Modelling most of the hyperparameters from https://catalog.ngc.nvidia.com/orgs/nvidia/teams/dle/resources/resnet_pyt\n",
    "episodes = 150\n",
    "optimizer = optim.SGD(\n",
    "    resnet.parameters(),\n",
    "    lr = batch_size / 1000, # linearly scale lr based on batch_size: https://arxiv.org/pdf/1706.02677.pdf%5B3%5D%20ImageNet\n",
    "    momentum = 0.875,\n",
    "    weight_decay = 1/32768\n",
    ")\n",
    "lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max = episodes\n",
    ")\n",
    "\n",
    "resnet_classifier = ResNetPredictor(\n",
    "    resnet,\n",
    "    optimizer = optimizer,\n",
    "    lr_scheduler = lr_scheduler,\n",
    "    mode = \"multi_label_classification\",\n",
    "    num_classes = len(train.classes),\n",
    "    dropout = 0.2,\n",
    "    optimize_predictor = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l1HeiR5QCJai"
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "episode_bar = tqdm(range(episodes))\n",
    "for episode in episode_bar:\n",
    "    print(f\"[Episode {episode + 1}]\")\n",
    "    # Train model using train data\n",
    "    y_true, y_pred, loss = resnet_classifier.step(trainloader, training = True)\n",
    "    f1_score = metrics.f1_score(y_true, y_pred, average = \"macro\") * 100\n",
    "    print(f\"Train Loss: {loss}\")\n",
    "    print(f\"Train F1-Score: {f1_score}%\")\n",
    "    episode_bar.set_description(f\"Train Loss: {loss}\")\n",
    "    writer.add_scalar(\"Train Loss (with Dropout)\", loss, episode)\n",
    "    writer.add_scalar(\"Train F1-Score (with Dropout)\", f1_score, episode)\n",
    "\n",
    "    # Evaluate every 5 epochs\n",
    "    if (episode + 1) % 5 == 0:\n",
    "        # Evaluate model using test data\n",
    "        y_true, y_pred, loss = resnet_classifier.step(testloader, training = False)\n",
    "        f1_score = metrics.f1_score(y_true, y_pred, average = \"macro\") * 100\n",
    "        print(f\"Test Loss: {loss}\")\n",
    "        print(f\"Test F1-Score: {f1_score}%\")\n",
    "        writer.add_scalar(\"Test Loss (without Dropout)\", loss, episode)\n",
    "        writer.add_scalar(\"Test F1-Score (without Dropout)\", f1_score, episode)\n",
    "\n",
    "    # Write last learning rate to log\n",
    "    writer.add_scalar(\"Learning Rate\", lr_scheduler.get_last_lr()[0], episode)\n",
    "\n",
    "    # Save model every 10 epochs\n",
    "    if (episode + 1) % 10 == 0:\n",
    "        resnet_classifier.save(MODEL_FOLDER + f\"resnet50_cifar100_episode{episode + 1}.safetensors\")\n",
    "\n",
    "calculate_gpu_utilization(0)\n",
    "writer.flush()\n",
    "writer.close()\n",
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fe-F7ND5INVD"
   },
   "source": [
    "# Evaluate ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bm8Kfho8CRoT"
   },
   "outputs": [],
   "source": [
    "mean, std = [0.50707516, 0.48654887, 0.44091784], [0.26733429, 0.25643846, 0.27615047]\n",
    "batch_size = 256\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "inverse_transform = transforms.Compose([\n",
    "    transforms.Normalize([-m/s for m, s in zip(mean, std)], [1/s for s in std]),\n",
    "    transforms.ToPILImage()\n",
    "])\n",
    "\n",
    "test = ModifiedCIFAR100(root = \"sample_data/cifar\", download = True, train = False, transform = transform_test)\n",
    "testloader = DataLoader(test, batch_size = batch_size)\n",
    "\n",
    "resnet = ResNet50()\n",
    "resnet_classifier = ResNetPredictor(\n",
    "    resnet,\n",
    "    mode = \"multi_label_classification\",\n",
    "    num_classes = len(test.classes),\n",
    "    dropout = 0.0\n",
    ")\n",
    "\n",
    "# Load and test model from episode 150\n",
    "resnet_classifier.load(MODEL_FOLDER + \"resnet50_cifar100_episode150.safetensors\")\n",
    "y_true, y_pred, loss = resnet_classifier.step(testloader, training = False)\n",
    "\n",
    "# Calculate metrics\n",
    "f1_score = metrics.f1_score(y_true, y_pred, average = \"macro\") * 100\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test F1-Score: {f1_score}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ueXmMXHuxkAP"
   },
   "outputs": [],
   "source": [
    "# Visualize tagging of predicted labels to their images\n",
    "rows, cols, scale = 15, 2, 8\n",
    "figure = plt.figure(figsize = (cols * scale, rows * scale))\n",
    "plt.rc(\"font\", size = 6)\n",
    "\n",
    "inputs, labels = next(iter(testloader))\n",
    "with torch.no_grad():\n",
    "    inputs, labels = inputs[:cols * rows].to(resnet_classifier.device), labels[:cols * rows].to(resnet_classifier.device)\n",
    "    logits, loss = resnet_classifier(inputs, labels)\n",
    "    labels = torch.nonzero(labels)[:, 1].view(-1, 2) # 1 coarse label + 1 fine label = 2 labels for each image\n",
    "    _, predictions = torch.topk(logits, 2, dim = 1) # displays 2 labels with the highest probabilities for simplistic visualization\n",
    "\n",
    "for i in range(rows * cols):\n",
    "    ax = figure.add_subplot(rows, cols, i + 1)\n",
    "    ax.set_title(f\"Ground truth: {[test.classes[labels[i][j]] for j in range(2)]}, Prediction: {[test.classes[predictions[i][j]] for j in range(2)]}\")\n",
    "    ax.axis(\"off\")\n",
    "    ax.imshow(inverse_transform(inputs[i]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
